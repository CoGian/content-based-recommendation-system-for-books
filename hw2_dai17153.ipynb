{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\kwgi\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\kwgi\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\kwgi\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "import string\n",
    "import csv\n",
    "from nltk.corpus import stopwords \n",
    "from nltk.tokenize import  word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.stem import PorterStemmer\n",
    "from py_stringmatching import  OverlapCoefficient\n",
    "from py_stringmatching import  Dice\n",
    "from py_stringmatching import  Jaccard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Αρχικά θα διαβάσουμε τα αρχεία και θα τα μετατρέψουμε σε dataframes ελέγχοντας για null τιμές και τα μεγέθη των dataframes.Η κωδικοποίηση για το διάβασμα όλων των αρχείων θα είναι cp437 γιατί η utf8 μου έβγαζε error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User-ID     False\n",
      "Location    False\n",
      "Age          True\n",
      "dtype: bool\n",
      "(278858, 3)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>User-ID</th>\n",
       "      <th>Location</th>\n",
       "      <th>Age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>nyc, new york, usa</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>stockton, california, usa</td>\n",
       "      <td>18.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>moscow, yukon territory, russia</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>porto, v.n.gaia, portugal</td>\n",
       "      <td>17.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>farnborough, hants, united kingdom</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   User-ID                            Location   Age\n",
       "0        1                  nyc, new york, usa   NaN\n",
       "1        2           stockton, california, usa  18.0\n",
       "2        3     moscow, yukon territory, russia   NaN\n",
       "3        4           porto, v.n.gaia, portugal  17.0\n",
       "4        5  farnborough, hants, united kingdom   NaN"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load users and print first 5  users\n",
    "users = pd.read_csv('BX-Users.csv',low_memory=False,sep=';',encoding='cp437')\n",
    "print(users.isna().any())\n",
    "print(users.shape)\n",
    "users.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Παραπάνω δεν μας πειράζει που υπάρχουν null τιμές στην στήλη \"Age\".\n",
    "Σε αυτό το σημείο χρειάζεται η υλοποίηση μιας μεθόδου που θα απομακρύνει κυρίως από τον τίτλο του βιβλίου κάποια σύμβολα που μπερδεύουν το pandas στην δημιουργία το dataframe books.Ο συνδυασμός συμβόλων επιλέχθηκαν εμπειρικά για να αφαιρεθούν."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transforming file BX-Books.csv to the right format for csv and pandas\n",
    "def transformCSV(inputfile,outputfile):\n",
    "    with open(inputfile,encoding='cp437') as fp1,open(outputfile,'w',encoding='cp437') as fp2:\n",
    "        line = fp1.readline()\n",
    "        while line:\n",
    "            if '&amp;' in line:\n",
    "                line= line.replace('&amp;',' ')\n",
    "            if ';\\\\' in line: \n",
    "                 line= line.replace(';\\\\',' ')\n",
    "            if '\"; ' in line: \n",
    "                 line= line.replace(\"'; \\'\",' ')  \n",
    "            if ' ; '  in line: \n",
    "                 line= line.replace(' ; ',' ')  \n",
    "            if '\"; '  in line: \n",
    "                 line= line.replace('\"; ',' ')  \n",
    "            fp2.write(line)\n",
    "            line = fp1.readline()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(271379, 4)\n",
      "ISBN                   False\n",
      "Book-Title             False\n",
      "Book-Author             True\n",
      "Year-Of-Publication    False\n",
      "dtype: bool\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ISBN</th>\n",
       "      <th>Book-Title</th>\n",
       "      <th>Book-Author</th>\n",
       "      <th>Year-Of-Publication</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0195153448</td>\n",
       "      <td>Classical Mythology</td>\n",
       "      <td>Mark P. O. Morford</td>\n",
       "      <td>2002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0002005018</td>\n",
       "      <td>Clara Callan</td>\n",
       "      <td>Richard Bruce Wright</td>\n",
       "      <td>2001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0060973129</td>\n",
       "      <td>Decision in Normandy</td>\n",
       "      <td>Carlo D'Este</td>\n",
       "      <td>1991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0374157065</td>\n",
       "      <td>Flu: The Story of the Great Influenza Pandemic...</td>\n",
       "      <td>Gina Bari Kolata</td>\n",
       "      <td>1999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0393045218</td>\n",
       "      <td>The Mummies of Urumchi</td>\n",
       "      <td>E. J. W. Barber</td>\n",
       "      <td>1999</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         ISBN                                         Book-Title  \\\n",
       "0  0195153448                                Classical Mythology   \n",
       "1  0002005018                                       Clara Callan   \n",
       "2  0060973129                               Decision in Normandy   \n",
       "3  0374157065  Flu: The Story of the Great Influenza Pandemic...   \n",
       "4  0393045218                             The Mummies of Urumchi   \n",
       "\n",
       "            Book-Author Year-Of-Publication  \n",
       "0    Mark P. O. Morford                2002  \n",
       "1  Richard Bruce Wright                2001  \n",
       "2          Carlo D'Este                1991  \n",
       "3      Gina Bari Kolata                1999  \n",
       "4       E. J. W. Barber                1999  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# transforming file BX-Book-Ratings.csv to the right format for csv and pandas\n",
    "transformCSV('BX-Books.csv','BX-Books-r.csv')\n",
    "# load books print first 5 books and print first 5 books\n",
    "books = pd.read_csv('BX-Books-r.csv',error_bad_lines=False, low_memory=False,sep=';',encoding='cp437')\n",
    "# get rid off unnecessary columns \n",
    "books = books[['ISBN','Book-Title','Book-Author','Year-Of-Publication']]\n",
    "print(books.shape)\n",
    "print(books.isna().any())\n",
    "books.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Παραπάνω δεν μας πειράζει που υπάρχουν null τιμές στην στήλη \"Book-Author\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1149780, 3)\n",
      "User-ID        False\n",
      "ISBN           False\n",
      "Book-Rating    False\n",
      "dtype: bool\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>User-ID</th>\n",
       "      <th>ISBN</th>\n",
       "      <th>Book-Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>276725</td>\n",
       "      <td>034545104X</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>276726</td>\n",
       "      <td>0155061224</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>276727</td>\n",
       "      <td>0446520802</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>276729</td>\n",
       "      <td>052165615X</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>276729</td>\n",
       "      <td>0521795028</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   User-ID        ISBN  Book-Rating\n",
       "0   276725  034545104X            0\n",
       "1   276726  0155061224            5\n",
       "2   276727  0446520802            0\n",
       "3   276729  052165615X            3\n",
       "4   276729  0521795028            6"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load ratings and print first 5 ratings \n",
    "ratings = pd.read_csv('BX-Book-Ratings.csv',low_memory=False,sep=';',encoding='cp437')\n",
    "print(ratings.shape)\n",
    "print(ratings.isna().any())\n",
    "ratings.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Μέσω μελέτης των δεδομένων παρατήρησα πως υπάρχουν κάποια ratings για βιβλία που δεν υπάρχουν για αυτό το λόγο αφαιρώ αυτά τα ratings και ελέγχω αν συμβαίνει το ίδιο και για τους χρήστες."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pruned ratings size:  (1031175, 3)\n",
      "Pruned ratings size:  (1031175, 3)\n"
     ]
    }
   ],
   "source": [
    "# prune ratings with books that don't exist \n",
    "ratings = ratings.merge(books[['ISBN']], how = 'inner' , on = 'ISBN' )\n",
    "print('Pruned ratings size: ' , ratings.shape)\n",
    "# prune ratings with users that don't exist \n",
    "ratings = ratings.merge(users[['User-ID']], how = 'inner' , on = 'User-ID' )\n",
    "print('Pruned ratings size: ' , ratings.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Όπως φαίνεται η παραπάνω υπόθεση που κάναμε ισχύει μόνο για τα βιβλία. Στην συνέχεια αφαιρούνται όλα τα βιβλία που έχουν λιγότερες από 10 βαθμολογίες και όλους οι χρήστες που έχουν βαθμολογήσει λιγότερα από 5 βιβλία η διαδικασία επαναλαμβάνεται μέχρι να μην υπάρξει καμία αλλαγή στα σύνολα δεδομένων."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ratings:  (385632, 3)\n",
      "users:  (10404, 3)\n",
      "books:  (12508, 4)\n"
     ]
    }
   ],
   "source": [
    "# intial sizes\n",
    "ratings_size = ratings.shape\n",
    "books_size = books.shape\n",
    "users_size = users.shape\n",
    "\n",
    "while True: \n",
    "\n",
    "    # prune all books that have less than 10 ratings  \n",
    "    ratings_count = pd.DataFrame(ratings.groupby('ISBN')['Book-Rating'].count())\n",
    "    ratings_count.rename(columns={'Book-Rating':'counts'},inplace = True)\n",
    "    ratings_count.reset_index(inplace =True)\n",
    "    ratings_count = ratings_count[ratings_count['counts'] > 10 ]\n",
    "    # update ratings\n",
    "    ratings = ratings.merge(ratings_count[['ISBN']], how = 'inner' , on = 'ISBN' )\n",
    "    \n",
    "    # prune all users that have less than 5 ratings \n",
    "    ratings_count = pd.DataFrame(ratings.groupby('User-ID')['Book-Rating'].count())\n",
    "    ratings_count.rename(columns={'Book-Rating':'counts'},inplace = True)\n",
    "    ratings_count.reset_index(inplace =True)\n",
    "    ratings_count = ratings_count[ratings_count['counts'] > 5 ]\n",
    "    # update ratings\n",
    "    ratings = ratings.merge(ratings_count[['User-ID']], how = 'inner' , on = 'User-ID' )\n",
    "\n",
    "    if ratings_size == ratings.shape and books_size == books.shape and users_size == users.shape: \n",
    "        break\n",
    "    else:\n",
    "        ratings_size = ratings.shape\n",
    "        books_size = books.shape\n",
    "        users_size = users.shape\n",
    "        \n",
    "# update dataframes\n",
    "books = books.merge(ratings[['ISBN']], how = 'inner' , on = 'ISBN' ).drop_duplicates()\n",
    "users = users.merge(ratings[['User-ID']],how = 'inner' , on = 'User-ID').drop_duplicates()    \n",
    "\n",
    "# print new sizes of ratings,users and books  \n",
    "print('ratings: ',ratings.shape)\n",
    "print('users: ',users.shape)\n",
    "print('books: ',books.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Όπως μπορείτε να δείτε, το σύνολο δεδομένων \"ratings\" μειώθηκε στις 385632 εγγραφές, το 'users' στις 10404 και το 'books' στις 12508.Παρακάτω υλοποιείτε μια μέθοδος για να παίρνουμε τον τίτλο του βιβλίου δίνοντας το ISBN του."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getbooknamefromISBN(ISBN):\n",
    "    return books.set_index('ISBN').loc[ISBN]['Book-Title']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The Alibi'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "getbooknamefromISBN(books['ISBN'].sample().tolist()[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Στην συνέχεια δημιουργούμε ένα πίνακα οφέλους απο τα ratings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>ISBN</th>\n",
       "      <th>0002251760</th>\n",
       "      <th>000649840X</th>\n",
       "      <th>0006547834</th>\n",
       "      <th>0006550576</th>\n",
       "      <th>0006550789</th>\n",
       "      <th>0007106572</th>\n",
       "      <th>0007110928</th>\n",
       "      <th>0007141076</th>\n",
       "      <th>0007154615</th>\n",
       "      <th>000716226X</th>\n",
       "      <th>...</th>\n",
       "      <th>3791513265</th>\n",
       "      <th>379200027X</th>\n",
       "      <th>3803112133</th>\n",
       "      <th>3822860867</th>\n",
       "      <th>8251800811</th>\n",
       "      <th>842046435X</th>\n",
       "      <th>8433925180</th>\n",
       "      <th>8495501198</th>\n",
       "      <th>8817125539</th>\n",
       "      <th>950491036X</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>User-ID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>99</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>114</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>243</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>244</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 12508 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "ISBN     0002251760  000649840X  0006547834  0006550576  0006550789  \\\n",
       "User-ID                                                               \n",
       "17              NaN         NaN         NaN         NaN         NaN   \n",
       "99              NaN         NaN         NaN         NaN         NaN   \n",
       "114             NaN         NaN         NaN         NaN         NaN   \n",
       "243             NaN         NaN         NaN         NaN         NaN   \n",
       "244             NaN         NaN         NaN         NaN         NaN   \n",
       "\n",
       "ISBN     0007106572  0007110928  0007141076  0007154615  000716226X  ...  \\\n",
       "User-ID                                                              ...   \n",
       "17              NaN         NaN         NaN         NaN         NaN  ...   \n",
       "99              NaN         NaN         NaN         NaN         NaN  ...   \n",
       "114             NaN         NaN         NaN         NaN         NaN  ...   \n",
       "243             NaN         NaN         NaN         NaN         NaN  ...   \n",
       "244             NaN         NaN         NaN         NaN         NaN  ...   \n",
       "\n",
       "ISBN     3791513265  379200027X  3803112133  3822860867  8251800811  \\\n",
       "User-ID                                                               \n",
       "17              NaN         NaN         NaN         NaN         NaN   \n",
       "99              NaN         NaN         NaN         NaN         NaN   \n",
       "114             NaN         NaN         NaN         NaN         NaN   \n",
       "243             NaN         NaN         NaN         NaN         NaN   \n",
       "244             NaN         NaN         NaN         NaN         NaN   \n",
       "\n",
       "ISBN     842046435X  8433925180  8495501198  8817125539  950491036X  \n",
       "User-ID                                                              \n",
       "17              NaN         NaN         NaN         NaN         NaN  \n",
       "99              NaN         NaN         NaN         NaN         NaN  \n",
       "114             NaN         NaN         NaN         NaN         NaN  \n",
       "243             NaN         NaN         NaN         NaN         NaN  \n",
       "244             NaN         NaN         NaN         NaN         NaN  \n",
       "\n",
       "[5 rows x 12508 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create the matrix of ISBN and corresponding user ratings\n",
    "user_book_rating = ratings.pivot_table(index='User-ID', columns='ISBN', values='Book-Rating')\n",
    "user_book_rating.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10404, 12508)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_book_rating.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Εδώ αρχίζει η προεπεξεργασία των τίτλων για την δημιουργία λέξεων κλειδιών. Με αυτόν τον κώδικα θέτουμε σε μια καινούρια στήλη \"KeyWords\" στο σύνολο δεδομένων books όλους τους τίτλους των βιβλίων με πεζά γράμματα."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                                  the kitchen god's wife\n",
       "24                                          the testament\n",
       "355                  beloved (plume contemporary fiction)\n",
       "496     our dumb century: the onion presents 100 years...\n",
       "511     new vegetarian: bold and beautiful recipes for...\n",
       "526                                           wild animus\n",
       "1748                                             airframe\n",
       "1911                                             timeline\n",
       "2197                                     prague : a novel\n",
       "2215                                          lying awake\n",
       "Name: KeyWords, dtype: object"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "books['KeyWords'] = books['Book-Title'].str.lower()\n",
    "books['KeyWords'].head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Παρακάτω αφαιρούμε τα σημεία στίξης"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove punctuations from Keywords(Title)\n",
    "def remove_punctuation(text):\n",
    "    no_punct = \"\".join([c for c in text if c not in string.punctuation])\n",
    "    return no_punct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                                   the kitchen gods wife\n",
       "24                                          the testament\n",
       "355                    beloved plume contemporary fiction\n",
       "496     our dumb century the onion presents 100 years ...\n",
       "511     new vegetarian bold and beautiful recipes for ...\n",
       "526                                           wild animus\n",
       "1748                                             airframe\n",
       "1911                                             timeline\n",
       "2197                                      prague  a novel\n",
       "2215                                          lying awake\n",
       "Name: KeyWords, dtype: object"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "books[\"KeyWords\"] = books[\"KeyWords\"].apply(lambda x : remove_punctuation(x))\n",
    "books[\"KeyWords\"].head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Στην συνέχεια κάνουμε tokenize."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                              [the, kitchen, gods, wife]\n",
       "24                                       [the, testament]\n",
       "355               [beloved, plume, contemporary, fiction]\n",
       "496     [our, dumb, century, the, onion, presents, 100...\n",
       "511     [new, vegetarian, bold, and, beautiful, recipe...\n",
       "526                                        [wild, animus]\n",
       "1748                                           [airframe]\n",
       "1911                                           [timeline]\n",
       "2197                                   [prague, a, novel]\n",
       "2215                                       [lying, awake]\n",
       "Name: KeyWords, dtype: object"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tokenize Keywords(Title)\n",
    "books[\"KeyWords\"] = books[\"KeyWords\"].fillna(\"\").map(word_tokenize)\n",
    "books[\"KeyWords\"].head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Έπειτα αφαιρούμε τα stopwords στα Αγγλικά."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove stopwords from Keywords \n",
    "def remove_stopwords(text):\n",
    "    words = [w for w in text if w not in stopwords.words('english')]\n",
    "    return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                                   [kitchen, gods, wife]\n",
       "24                                            [testament]\n",
       "355               [beloved, plume, contemporary, fiction]\n",
       "496     [dumb, century, onion, presents, 100, years, h...\n",
       "511     [new, vegetarian, bold, beautiful, recipes, ev...\n",
       "526                                        [wild, animus]\n",
       "1748                                           [airframe]\n",
       "1911                                           [timeline]\n",
       "2197                                      [prague, novel]\n",
       "2215                                       [lying, awake]\n",
       "Name: KeyWords, dtype: object"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "books[\"KeyWords\"] = books[\"KeyWords\"].apply(lambda x : remove_stopwords(x))\n",
    "books[\"KeyWords\"].head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Τέλος έχουμε την επιλογή να χρησιμοποιήσουμε είτε lemmatizer είτε stemmer για να κόψουμε τις καταλήξεις των λέξεων. Εγώ χρησιμοποιώ stemmer γιατί πιστεύω είναι ποιο χρήσιμος λόγο του μικρού μεγέθους των τίτλων."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate lemmatizer \n",
    "lemmatizer = WordNetLemmatizer()\n",
    "def word_lemmatizer(text):\n",
    "    lem_text = \" \".join([lemmatizer.lemmatize(i) for i in text])\n",
    "    return lem_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate Stemmer \n",
    "stemmer = PorterStemmer()\n",
    "def word_stemmer(text):\n",
    "    stem_text = [stemmer.stem(i) for i in text]\n",
    "    return stem_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                                    [kitchen, god, wife]\n",
       "24                                            [testament]\n",
       "355                 [belov, plume, contemporari, fiction]\n",
       "496     [dumb, centuri, onion, present, 100, year, hea...\n",
       "511     [new, vegetarian, bold, beauti, recip, everi, ...\n",
       "526                                         [wild, animu]\n",
       "1748                                            [airfram]\n",
       "1911                                            [timelin]\n",
       "2197                                       [pragu, novel]\n",
       "2215                                          [lie, awak]\n",
       "Name: KeyWords, dtype: object"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "books[\"KeyWords\"] = books[\"KeyWords\"].apply(lambda x : word_stemmer(x))\n",
    "books[\"KeyWords\"].head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Στην συνέχεια υλοποιώ μια μέθοδο για να παίρνω τα 3 βιβλία με την υψηλότερη βαθμολογία για έναν χρήστη καθώς και όλα τα βιβλία που έχει βαθμολογήσει"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find 3 books' ISBN with the highest rating from the user and return them with all the books user has rated\n",
    "def get3largest_values(user):\n",
    "    user_books = user_book_rating.loc[user].dropna()\n",
    "    return user_books ,user_books.nlargest(3,keep = \"first\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          ISBN  49212                                         Book-Title\n",
      "0   0060936363    0.0                        Portrait in Sepia : A Novel\n",
      "1   006440188X   10.0                                  The Secret Garden\n",
      "2   0312201656    4.0                               I Capture the Castle\n",
      "3   0345348109    0.0                                  The Killer Angels\n",
      "4   0345370775    8.0                                      Jurassic Park\n",
      "5   0375422307    9.0  Persepolis : The Story of a Childhood (Alex Aw...\n",
      "6   0380724987    0.0  Justice (Peter Decker   Rina Lazarus Novels (P...\n",
      "7   0425154092    8.0                                From Potter's Field\n",
      "8   0440212723    0.0                                    Cold Sassy Tree\n",
      "9   0440213525    8.0                                         The Client\n",
      "10  044022165X    0.0                                      The Rainmaker\n",
      "11  0446315176    9.0                      An Unsuitable Job for a Woman\n",
      "12  0446363251    6.0  Scarlett : The Sequel to Margaret Mitchell's \\...\n",
      "13  0446364622    0.0                                The Children of Men\n",
      "14  0446602345    0.0                                       Original Sin\n",
      "15  0446605239    5.0                                       The Notebook\n",
      "16  0446692298    0.0                          Fat Girls and Lawn Chairs\n",
      "17  0449207544    9.0                                              Proof\n",
      "18  0449211479    8.0                                         The Source\n",
      "19  0449213447    0.0                                         The Chosen\n",
      "20  0553299506    9.0    Private Eyes (Alex Delaware Novels (Paperback))\n",
      "21  0553574558    0.0                                   To Play the Fool\n",
      "22  0553581279   10.0                             The Silver Metal Lover\n",
      "23  0670030643    6.0             The Eyre Affair (Alex Awards (Awards))\n",
      "24  067168390X    9.0                                      Lonesome Dove\n",
      "25  0679741836    0.0               Molly Ivins Can't Say That, Can She?\n",
      "26  0679763309    0.0                                    An Unquiet Mind\n",
      "27  0679772677    0.0                                     A Civil Action\n",
      "28  0689711816   10.0  From the Mixed-Up Files of Mrs. Basil E. Frank...\n",
      "29  0765342987    7.0                                     Kushiel's Dart\n",
      "30  0786817070    5.0                Artemis Fowl (Artemis Fowl, Book 1)\n",
      "31  0804115761    6.0                                     Thousand Acres\n",
      "32  1400034779    8.0  The No. 1 Ladies' Detective Agency (Today Show...\n",
      "33  1573225789    8.0  The Color of Water: A Black Man's Tribute to H...\n",
      "Favourite books: \n",
      "         ISBN  49212                                         Book-Title\n",
      "0  006440188X   10.0                                  The Secret Garden\n",
      "1  0553581279   10.0                             The Silver Metal Lover\n",
      "2  0689711816   10.0  From the Mixed-Up Files of Mrs. Basil E. Frank...\n"
     ]
    }
   ],
   "source": [
    "user_books , fav_books = get3largest_values(users['User-ID'].sample().tolist()[0])\n",
    "# print 10 books rated from user \n",
    "user_books = user_books.reset_index()\n",
    "user_books[\"Book-Title\"] = user_books[\"ISBN\"].apply(lambda x : getbooknamefromISBN(x))\n",
    "print(user_books)\n",
    "# print favourite books \n",
    "print(\"Favourite books: \")\n",
    "fav_books = fav_books.reset_index()\n",
    "fav_books[\"Book-Title\"] = fav_books[\"ISBN\"].apply(lambda x : getbooknamefromISBN(x))\n",
    "print(fav_books)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Μέθοδος που δημιουργεί ένα “προφίλ” προτιμήσεων του χρήστη με βάση την\n",
    "ένωση των λέξεων κλειδιών των 3 βιβλίων, τους συγγραφείς τους και το έτος\n",
    "έκδοσης τους και επιστρέφει όλα αυτά και τα ISBN των βιβλίων που έχει βαθμολογήσει."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_user_profile(user):\n",
    "    # get  readed and favourites books of user  \n",
    "    user_books , fav_books = get3largest_values(user)\n",
    "    \n",
    "    # initialize \n",
    "    keywords = []\n",
    "    authors = [] \n",
    "    years_of_publication = []\n",
    "    \n",
    "    for book in fav_books.index:\n",
    "            keywords += books.set_index('ISBN').loc[book]['KeyWords']\n",
    "            authors.append(books.set_index('ISBN').loc[book]['Book-Author'])\n",
    "            years_of_publication.append(books.set_index('ISBN').loc[book]['Year-Of-Publication'])\n",
    "    return keywords, authors, years_of_publication , user_books"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['art', 'decept', 'black', 'ice', 'detect', 'harri', 'bosch', 'mysteri', 'kill', 'shadow', 'st', 'martin', 'minotaur', 'mysteri'] ['Ridley Pearson', 'Michael Connelly', 'Val McDermid'] ['2003', '1996', '2002']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ISBN</th>\n",
       "      <th>31822</th>\n",
       "      <th>Book-Title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0312952813</td>\n",
       "      <td>8.0</td>\n",
       "      <td>The Black Ice (Detective Harry Bosch Mysteries)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0312983387</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Killing the Shadows (St. Martin's Minotaur Mys...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0425185168</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Forty Words for Sorrow</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0440222826</td>\n",
       "      <td>0.0</td>\n",
       "      <td>The Mercy Rule</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0451178017</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Over the Edge</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0515128821</td>\n",
       "      <td>0.0</td>\n",
       "      <td>The Breaker</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0786890002</td>\n",
       "      <td>9.0</td>\n",
       "      <td>The Art of Deception</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         ISBN  31822                                         Book-Title\n",
       "0  0312952813    8.0    The Black Ice (Detective Harry Bosch Mysteries)\n",
       "1  0312983387    0.0  Killing the Shadows (St. Martin's Minotaur Mys...\n",
       "2  0425185168    0.0                             Forty Words for Sorrow\n",
       "3  0440222826    0.0                                     The Mercy Rule\n",
       "4  0451178017    0.0                                      Over the Edge\n",
       "5  0515128821    0.0                                        The Breaker\n",
       "6  0786890002    9.0                               The Art of Deception"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "profile = make_user_profile(users['User-ID'].sample().tolist()[0])\n",
    "print(profile[0],profile[1],profile[2])\n",
    "user_books  = profile[3]\n",
    "user_books = user_books.reset_index()\n",
    "user_books[\"Book-Title\"] = user_books[\"ISBN\"].apply(lambda x : getbooknamefromISBN(x))\n",
    "user_books"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "H ομοιότητα Jaccard βασισμένη στον τύπο $ J(X,Y) = |X∩Y| / |X∪Y| $ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def jaccard_similarity(x,y): \n",
    "    intersection_cardinality = len(set(x) & set(y))\n",
    "    union_cardinality = len(set(x) | set(y))\n",
    "    return intersection_cardinality/float(union_cardinality)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3333333333333333"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jaccard_similarity([\"hallo\",\"world\"] ,[\"hello\",\"world\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Έλεγχος για το αν υλοποιήθηκε σωστά."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3333333333333333"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "j = Jaccard()\n",
    "j.get_raw_score([\"hallo\",\"world\"] ,[\"hello\",\"world\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "H ομοιότητα Dice coefficient βασισμένη στον τύπο $DSC(X,Y) = 2|X∩Y| / (|X|+|Y|)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dice_coefficient(a, b):\n",
    "    \"\"\"dice coefficient 2nt/(na + nb).\"\"\"\n",
    "    a_bigrams = set(a)\n",
    "    b_bigrams = set(b)\n",
    "    overlap = len(a_bigrams & b_bigrams)\n",
    "    return overlap * 2.0/(len(a_bigrams) + len(b_bigrams))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dice_coefficient([\"hallo\",\"world\"] ,[\"hello\",\"world\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Έλεγχος για το αν υλοποιήθηκε σωστά "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dice = Dice()\n",
    "dice.get_raw_score([\"hallo\",\"world\"] ,[\"hello\",\"world\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Μέθοδος που υπολογίζει την ομοιότητα ενός βιβλίου με το “προφίλ” προτιμήσεων ενός χρήστη και ανάλογα το mode που θα επιλέξουμε επιστρέφει την ομοιότητα.(για mode = 1 η ομοιότητά υπολογίζεται ως εξής : Jaccard για τις λέξεις κλειδιά με βάρος 0.2, ισότητα για τους συγγραφείς 0.4,διαφορά ετών έκδοσης 0.4 και για mode = 2 : Dice coefficient για τις λέξεις κλειδιά με βάρος 0.5, ισότητα για τους συγγραφείς 0.3, διαφορά ετών έκδοσης 0.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_similarity(user_profile,book,mode):\n",
    "    # get keywords \n",
    "    profile_keywords = user_profile[0]\n",
    "    book_keywords = book['KeyWords']\n",
    "    \n",
    "    # get author \n",
    "    profile_authors =  user_profile[1]\n",
    "    book_author = book['Book-Author']\n",
    "    \n",
    "    # get years \n",
    "    profile_years =  user_profile[2]\n",
    "    book_year = book['Year-Of-Publication']\n",
    "    \n",
    "    # calculate keywords_similarity \n",
    "    if mode == 1:\n",
    "        keywords_similarity = jaccard_similarity(profile_keywords,book_keywords)\n",
    "    elif mode == 2:\n",
    "        keywords_similarity = dice_coefficient(profile_keywords,book_keywords)\n",
    "    else:\n",
    "        print(\"mode is missing or is incoreect\")\n",
    "        pass\n",
    "    # calculate author similarity \n",
    "    if book_author in profile_authors:\n",
    "        author_similarity = 1 \n",
    "    else:\n",
    "        author_similarity = 0\n",
    "    \n",
    "    # calculate years similarity\n",
    "    year_similarity = min([1-(abs(int(x)-int(book_year))/2005) for x in profile_years])\n",
    "    \n",
    "    if mode == 1:\n",
    "        return 0.2 * keywords_similarity + 0.4 * author_similarity + 0.4 * year_similarity\n",
    "    elif mode==2:\n",
    "        return 0.5 * keywords_similarity + 0.3 * author_similarity + 0.2 * year_similarity\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ISBN                                                          0312982011\n",
      "Book-Title             Abandoned Prayers: The Shocking True Story of ...\n",
      "Book-Author                                                  Gregg Olsen\n",
      "Year-Of-Publication                                                 2002\n",
      "KeyWords               [abandon, prayer, shock, true, stori, obsess, ...\n",
      "Name: 365238, dtype: object\n",
      "Similarity(mode=1) :  0.39880299251870327\n",
      "Similarity(mode=2) :  0.19940149625935163\n"
     ]
    }
   ],
   "source": [
    "# calculate similarity between profile that already have and random book\n",
    "location = books['ISBN'].sample().tolist()[0]\n",
    "book = books.loc[books.sample().index.tolist()[0]]\n",
    "print(book)\n",
    "print(\"Similarity(mode=1) : \",calc_similarity(profile,book,1))\n",
    "print(\"Similarity(mode=2) : \",calc_similarity(profile,book,2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Μέθοδος που προτείνει στον χρήστη τα 10 αντικείμενα (που δεν έχει βαθμολογήσει) τα οποία\n",
    "είναι ομοιότερα με το προφίλ του, διατεταγμένα από το περισσότερο προς το\n",
    "λιγότερο όμοιο."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recommend(user_profile,mode):\n",
    "    books_similarity = pd.DataFrame(books['ISBN'])\n",
    "    books_similarity['similarity'] = None \n",
    "    for index,book in books.iterrows():\n",
    "        if book['ISBN'] not in user_profile[3].index:\n",
    "            books_similarity.loc[index]['similarity'] =  calc_similarity(user_profile,book,mode)\n",
    "    \n",
    "    return books_similarity.sort_values(['similarity'],ascending=False).dropna().head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ISBN</th>\n",
       "      <th>similarity</th>\n",
       "      <th>Book-Title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>150630</td>\n",
       "      <td>0312950489</td>\n",
       "      <td>0.869434</td>\n",
       "      <td>The Black Echo (Detective Harry Bosch Mysteries)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>209582</td>\n",
       "      <td>0316152196</td>\n",
       "      <td>0.852535</td>\n",
       "      <td>Angels Flight (Detective Harry Bosch Mysteries)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>183826</td>\n",
       "      <td>0446607274</td>\n",
       "      <td>0.852535</td>\n",
       "      <td>Angels Flight (Detective Harry Bosch Mysteries)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>301603</td>\n",
       "      <td>0312963297</td>\n",
       "      <td>0.852336</td>\n",
       "      <td>Trunk Music (Detective Harry Bosch Mysteries)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>351556</td>\n",
       "      <td>0786867248</td>\n",
       "      <td>0.829572</td>\n",
       "      <td>The Art of Deception</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>333481</td>\n",
       "      <td>0446613444</td>\n",
       "      <td>0.829373</td>\n",
       "      <td>The Black Ice</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>205084</td>\n",
       "      <td>0312955006</td>\n",
       "      <td>0.823404</td>\n",
       "      <td>The Concrete Blonde (A Harry Bosch Novel)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>214761</td>\n",
       "      <td>0446612731</td>\n",
       "      <td>0.813089</td>\n",
       "      <td>The Black Echo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>257972</td>\n",
       "      <td>0312983603</td>\n",
       "      <td>0.808803</td>\n",
       "      <td>The Mermaids Singing (A Dr. Tony Hill   Carol ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>68302</td>\n",
       "      <td>0312983654</td>\n",
       "      <td>0.808803</td>\n",
       "      <td>The Wire in the Blood (A Dr. Tony Hill   Carol...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              ISBN similarity  \\\n",
       "150630  0312950489   0.869434   \n",
       "209582  0316152196   0.852535   \n",
       "183826  0446607274   0.852535   \n",
       "301603  0312963297   0.852336   \n",
       "351556  0786867248   0.829572   \n",
       "333481  0446613444   0.829373   \n",
       "205084  0312955006   0.823404   \n",
       "214761  0446612731   0.813089   \n",
       "257972  0312983603   0.808803   \n",
       "68302   0312983654   0.808803   \n",
       "\n",
       "                                               Book-Title  \n",
       "150630   The Black Echo (Detective Harry Bosch Mysteries)  \n",
       "209582    Angels Flight (Detective Harry Bosch Mysteries)  \n",
       "183826    Angels Flight (Detective Harry Bosch Mysteries)  \n",
       "301603      Trunk Music (Detective Harry Bosch Mysteries)  \n",
       "351556                               The Art of Deception  \n",
       "333481                                      The Black Ice  \n",
       "205084          The Concrete Blonde (A Harry Bosch Novel)  \n",
       "214761                                     The Black Echo  \n",
       "257972  The Mermaids Singing (A Dr. Tony Hill   Carol ...  \n",
       "68302   The Wire in the Blood (A Dr. Tony Hill   Carol...  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculate and print recomended books with first mode  \n",
    "recomended_books1 = recommend(profile,1)\n",
    "recomended_books1[\"Book-Title\"] = recomended_books1[\"ISBN\"].apply(lambda x : getbooknamefromISBN(x))\n",
    "recomended_books1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ISBN</th>\n",
       "      <th>similarity</th>\n",
       "      <th>Book-Title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>150630</td>\n",
       "      <td>0312950489</td>\n",
       "      <td>0.76216</td>\n",
       "      <td>The Black Echo (Detective Harry Bosch Mysteries)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>209582</td>\n",
       "      <td>0316152196</td>\n",
       "      <td>0.710127</td>\n",
       "      <td>Angels Flight (Detective Harry Bosch Mysteries)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>183826</td>\n",
       "      <td>0446607274</td>\n",
       "      <td>0.710127</td>\n",
       "      <td>Angels Flight (Detective Harry Bosch Mysteries)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>301603</td>\n",
       "      <td>0312963297</td>\n",
       "      <td>0.710028</td>\n",
       "      <td>Trunk Music (Detective Harry Bosch Mysteries)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>351556</td>\n",
       "      <td>0786867248</td>\n",
       "      <td>0.632735</td>\n",
       "      <td>The Art of Deception</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>333481</td>\n",
       "      <td>0446613444</td>\n",
       "      <td>0.632635</td>\n",
       "      <td>The Black Ice</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>205084</td>\n",
       "      <td>0312955006</td>\n",
       "      <td>0.610313</td>\n",
       "      <td>The Concrete Blonde (A Harry Bosch Novel)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>214761</td>\n",
       "      <td>0446612731</td>\n",
       "      <td>0.566068</td>\n",
       "      <td>The Black Echo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>257972</td>\n",
       "      <td>0312983603</td>\n",
       "      <td>0.547021</td>\n",
       "      <td>The Mermaids Singing (A Dr. Tony Hill   Carol ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>68302</td>\n",
       "      <td>0312983654</td>\n",
       "      <td>0.547021</td>\n",
       "      <td>The Wire in the Blood (A Dr. Tony Hill   Carol...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              ISBN similarity  \\\n",
       "150630  0312950489    0.76216   \n",
       "209582  0316152196   0.710127   \n",
       "183826  0446607274   0.710127   \n",
       "301603  0312963297   0.710028   \n",
       "351556  0786867248   0.632735   \n",
       "333481  0446613444   0.632635   \n",
       "205084  0312955006   0.610313   \n",
       "214761  0446612731   0.566068   \n",
       "257972  0312983603   0.547021   \n",
       "68302   0312983654   0.547021   \n",
       "\n",
       "                                               Book-Title  \n",
       "150630   The Black Echo (Detective Harry Bosch Mysteries)  \n",
       "209582    Angels Flight (Detective Harry Bosch Mysteries)  \n",
       "183826    Angels Flight (Detective Harry Bosch Mysteries)  \n",
       "301603      Trunk Music (Detective Harry Bosch Mysteries)  \n",
       "351556                               The Art of Deception  \n",
       "333481                                      The Black Ice  \n",
       "205084          The Concrete Blonde (A Harry Bosch Novel)  \n",
       "214761                                     The Black Echo  \n",
       "257972  The Mermaids Singing (A Dr. Tony Hill   Carol ...  \n",
       "68302   The Wire in the Blood (A Dr. Tony Hill   Carol...  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculate and print recomended books with second mode  \n",
    "recomended_books2 = recommend(profile,2)\n",
    "recomended_books2[\"Book-Title\"] = recomended_books2[\"ISBN\"].apply(lambda x : getbooknamefromISBN(x))\n",
    "recomended_books2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Εδω ξεκινάει το πείραμα.Επιλέγουμε τυχαία 5 χρήστες και παράγουμε για\n",
    "αυτούς τις σχετικές προτάσεις και με τις δύο εναλλακτικές, οι οποίες και θα\n",
    "καταγράφουν σε αντίστοιχα αρχεία εξόδου (διαφορετικά)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_predictions():\n",
    "    # random sample of 5 users \n",
    "    sampled_users = users['User-ID'].sample(5).tolist()\n",
    "\n",
    "    for user in sampled_users:\n",
    "        # make user's profile \n",
    "        profile = make_user_profile(user)\n",
    "\n",
    "        # recomend 10 books with first method\n",
    "        recomended_books1 = recommend(profile,1)\n",
    "        recomended_books1[\"Book-Title\"] = recomended_books1[\"ISBN\"].apply(lambda x : getbooknamefromISBN(x))\n",
    "\n",
    "        # recomend 10 books with the second method\n",
    "        recomended_books2 = recommend(profile,2)\n",
    "        recomended_books2[\"Book-Title\"] = recomended_books2[\"ISBN\"].apply(lambda x : getbooknamefromISBN(x))\n",
    "\n",
    "        # save them \n",
    "        recomended_books1.to_csv(str(user)+'_1.csv',index= None,encoding='cp437')\n",
    "        recomended_books2.to_csv(str(user)+'_2.csv',index= None,encoding='cp437')\n",
    "    \n",
    "    # save sampled users \n",
    "    with open('sampled_users.csv', 'w', newline='') as myfile:\n",
    "        wr = csv.writer(myfile, quoting=csv.QUOTE_ALL)\n",
    "        wr.writerow(sampled_users)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "make_predictions()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Για κάθε χρήστη που τυχαία επέλεξε προηγουμένως, μετραει την ομοιότητα των λιστών με τα αποτέλεσματα\n",
    "υπολογίζοντας τη μέση επικάλυψη τους και τα επιστρέφει μαζί με 2 λίστες που έχουν τα αποτελέσματα των χρηστών.Πρωτα πρέπει να φτιαχτεί μια μέθοδος για να μετράμε την επικάλυψη βάση του τύπου $overlap_coefficient(X,Y)=|X∩Y|/min(|X|,|Y|)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def overlap(x,y):\n",
    "    intersection_cardinality = len(set(x) & set(y))\n",
    "    return intersection_cardinality / min(len(set(x)),len(set(y)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "overlap([\"hallo\",\"world\"] ,[\"hello\",\"world\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Έλεγχος για το αν υλοποιήθηκε σωστά. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "oc = OverlapCoefficient()\n",
    "oc.get_raw_score([\"hallo\",\"world\"] ,[\"hello\",\"world\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_sampled_users():\n",
    "    sampled_users = [] \n",
    "    with open('sampled_users.csv', 'r') as f:\n",
    "        reader = csv.reader(f)\n",
    "        sampled_users = list(reader)[0]\n",
    "    return sampled_users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['77585', '142005', '135753', '10660', '232964']\n"
     ]
    }
   ],
   "source": [
    "# read the User-ID fro sampled users  \n",
    "sampled_users = read_sampled_users()\n",
    "print(sampled_users)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_recomended_books(sampled_users):\n",
    "    # lists with recomended books for every user \n",
    "    recomended_books1_list = []\n",
    "    recomended_books2_list = [] \n",
    "    \n",
    "    for user in sampled_users:\n",
    "        # read recomended_books with first method\n",
    "        recomended_books1 = pd.read_csv(str(user) + '_1.csv',low_memory=False,encoding='cp437',dtype={'ISBN': str})\n",
    "        recomended_books1_list.append(recomended_books1)\n",
    "        # read recomended_books with second method\n",
    "        recomended_books2 = pd.read_csv(str(user) + '_2.csv',low_memory=False,encoding='cp437',dtype={'ISBN': str})\n",
    "        recomended_books2_list.append(recomended_books2)\n",
    "    \n",
    "    return recomended_books1_list,recomended_books2_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         ISBN  similarity                              Book-Title\n",
      "0  0345410017    0.855347                          Fahrenheit 451\n",
      "1  0312169787    0.848005                  The Red Tent : A Novel\n",
      "2  0345380371    0.798404                              Rising Sun\n",
      "3  0345378482    0.798404                    The Andromeda Strain\n",
      "4  0394588169    0.798005                           Jurassic Park\n",
      "5  0345354648    0.797805                           Five Patients\n",
      "6  0345354613    0.797606                      Eaters of the Dead\n",
      "7  0345353145    0.797606                                  Sphere\n",
      "8  0743225325    0.797207                    Good Harbor: A Novel\n",
      "9  0553277537    0.797007  Dandelion Wine (Grand Master Editions)\n",
      "         ISBN  similarity                              Book-Title\n",
      "0  0345410017    0.721324                          Fahrenheit 451\n",
      "1  0312169787    0.699002                  The Red Tent : A Novel\n",
      "2  0345380371    0.499202                              Rising Sun\n",
      "3  0345378482    0.499202                    The Andromeda Strain\n",
      "4  0394588169    0.499002                           Jurassic Park\n",
      "5  0345354648    0.498903                           Five Patients\n",
      "6  0345354613    0.498803                      Eaters of the Dead\n",
      "7  0345353145    0.498803                                  Sphere\n",
      "8  0743225325    0.498603                    Good Harbor: A Novel\n",
      "9  0553277537    0.498504  Dandelion Wine (Grand Master Editions)\n"
     ]
    }
   ],
   "source": [
    "# read reconmended books\n",
    "recomended_books1_list , recomended_books2_list = read_recomended_books(sampled_users)\n",
    "# print first sampled user recomended books \n",
    "print(recomended_books1_list[0])\n",
    "print(recomended_books2_list[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_weighted_overlap(recomended_books1,recomended_books2):\n",
    "    weighted_overlap = 0\n",
    "    sum_overlap = 0 \n",
    "    for i in range(10):\n",
    "        # get isbn\n",
    "        isbn1 = recomended_books1.iloc[i, 0] \n",
    "        isbn2 = recomended_books2.iloc[i, 0]\n",
    "        \n",
    "        # get books \n",
    "        book1 = books.set_index('ISBN').loc[str(isbn1)]\n",
    "        book2 = books.set_index('ISBN').loc[str(isbn2)]\n",
    "\n",
    "        # make lists with books charachteristics \n",
    "        book1_ch = book1['KeyWords'] + [book1['Book-Author']] + [book1['Year-Of-Publication']]\n",
    "        book2_ch = book2['KeyWords'] + [book2['Book-Author']] + [book2['Year-Of-Publication']]\n",
    "        # update sum overlap \n",
    "        sum_overlap += overlap(book1_ch,book2_ch)\n",
    "    \n",
    "    # compute weighted_overlap\n",
    "    weighted_overlap = sum_overlap/10\n",
    "\n",
    "    return weighted_overlap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weighted_Overlaps\n",
      "User:  77585   1.0\n",
      "User:  142005   0.925\n",
      "User:  135753   0.9333333333333333\n",
      "User:  10660   1.0\n",
      "User:  232964   0.975\n"
     ]
    }
   ],
   "source": [
    "# calculate weighted_overlaps for every user  \n",
    "weighted_overlaps = []       \n",
    "\n",
    "for i in range(5):    \n",
    "    weighted_overlap = calc_weighted_overlap(recomended_books1_list[i],recomended_books2_list[i])\n",
    "    weighted_overlaps.append(weighted_overlap)\n",
    "\n",
    "print('Weighted_Overlaps')\n",
    "for i in range(5):\n",
    "    print('User: ',sampled_users[i],\" \",weighted_overlaps[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Για κάθε χρήστη, υπολογίζει σε πόσες λίστες εμφανίζεται το κάθε αποτέλεσμα και\n",
    "ταξινομει τα σε μία νέα λίστα—πρώτα με βάση του πλήθους εμφανίσεων και\n",
    "μετά με βάση την ομοιότητα με το προφίλ του χρήστη."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_occurancies(recomended_book,recomended_books_list):\n",
    "    count = 0 \n",
    "    for books in recomended_books_list:\n",
    "        if recomended_book['ISBN'] in books['ISBN'].tolist():\n",
    "            count += 1\n",
    "    return count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Μέθοδος δημιουργίας golden standard δωσμένου μιας λίστας ενος χρήστη και την λίστα με τις λίστες όλων των χρηστών."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_golden_standard(recomended_books,recomended_books_list):\n",
    "    counts = []\n",
    "    for index,book in recomended_books.iterrows():\n",
    "        counts.append(count_occurancies(book,recomended_books_list))\n",
    "    recomended_books['count'] = counts\n",
    "    golden_standard = recomended_books.sort_values(by=['count','similarity'],ascending=False)\n",
    "    \n",
    "    return golden_standard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create golden standards and save them to cvs \n",
    "golden_standards1 = []\n",
    "golden_standards2 = []\n",
    "for i in range(5):\n",
    "    # golden standard with Jaccard \n",
    "    golden_standard1 = make_golden_standard(recomended_books1_list[i],recomended_books1_list)\n",
    "    golden_standards1.append(golden_standard1)\n",
    "    \n",
    "    # golden standard with Dice\n",
    "    golden_standard2 = make_golden_standard(recomended_books2_list[i],recomended_books2_list)\n",
    "    golden_standards2.append(golden_standard2)\n",
    "    \n",
    "    # save them \n",
    "    golden_standard1.to_csv('golden' + str(sampled_users[i])+'_1.csv',index= None,encoding='cp437')\n",
    "    golden_standard2.to_csv('golden' + str(sampled_users[i])+'_2.csv',index= None,encoding='cp437')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Eπανάλάψη του βήματος 2 συγκρίνει όμως κάθε λίστα\n",
    "με την golden_standard που παράχθηκε (μέχρι το 10 της στοιχείο)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weighted_Overlaps_1\n",
      "User:  77585   1.0\n",
      "User:  142005   1.0\n",
      "User:  135753   0.575\n",
      "User:  10660   1.0\n",
      "User:  232964   0.3678571428571429\n",
      "\n",
      "Weighted_Overlaps_2\n",
      "User:  77585   1.0\n",
      "User:  142005   1.0\n",
      "User:  135753   0.575\n",
      "User:  10660   1.0\n",
      "User:  232964   0.3678571428571429\n"
     ]
    }
   ],
   "source": [
    "weighted_overlaps1 = []       \n",
    "weighted_overlaps2 = []    \n",
    "for i in range(5):    \n",
    "    weighted_overlap = calc_weighted_overlap(recomended_books1_list[i],golden_standards1[i])\n",
    "    weighted_overlaps1.append(weighted_overlap)\n",
    "    \n",
    "    weighted_overlap = calc_weighted_overlap(recomended_books2_list[i],golden_standards2[i])\n",
    "    weighted_overlaps2.append(weighted_overlap)\n",
    "\n",
    "print('Weighted_Overlaps_1')\n",
    "for i in range(5):\n",
    "    print('User: ',sampled_users[i],\" \",weighted_overlaps1[i])\n",
    "    \n",
    "print('\\nWeighted_Overlaps_2')\n",
    "for i in range(5):\n",
    "    print('User: ',sampled_users[i],\" \",weighted_overlaps2[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
